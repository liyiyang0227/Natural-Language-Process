{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c6c6cc539864fcfb687d6167540870d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_76121b41412942db8f10d4a70f07ee3d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_602d763d9eda40b99a421bb9ac7aa2a4",
              "IPY_MODEL_d7195b068524495d90eba1fd04e0e96d"
            ]
          }
        },
        "76121b41412942db8f10d4a70f07ee3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "602d763d9eda40b99a421bb9ac7aa2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e2c179be10314ee099e2f184631cf9a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3670f80401cd4b8491938b83ee02c4be"
          }
        },
        "d7195b068524495d90eba1fd04e0e96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c75757d71f434bae9709815266b98d00",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 10/10 [00:19&lt;00:00,  1.94s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c518b896402e405e80974eb0160e50f7"
          }
        },
        "e2c179be10314ee099e2f184631cf9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3670f80401cd4b8491938b83ee02c4be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c75757d71f434bae9709815266b98d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c518b896402e405e80974eb0160e50f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78aebb861fc3489b9844d566e5b49466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1f45e88ee6948889a34f14f139c380f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58a019b309ad461e90256b1f5a48e504",
              "IPY_MODEL_aef5e9fa02c84325a9180afd654a9e73"
            ]
          }
        },
        "e1f45e88ee6948889a34f14f139c380f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58a019b309ad461e90256b1f5a48e504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28648255724042df96e6049882560ca1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd986fb29c7249c6877d80c38440f6c4"
          }
        },
        "aef5e9fa02c84325a9180afd654a9e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5de64b3e6a3746088ac3f7354e7ce250",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 20/20 [02:08&lt;00:00,  6.43s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b62c3bc4280b4f1ea8f92c36ad1c27ae"
          }
        },
        "28648255724042df96e6049882560ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd986fb29c7249c6877d80c38440f6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5de64b3e6a3746088ac3f7354e7ce250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b62c3bc4280b4f1ea8f92c36ad1c27ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IPo0cuBadK3",
        "colab_type": "text"
      },
      "source": [
        "# Download environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjNJ0Z1HesWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx3Ja9zWFDj2",
        "colab_type": "code",
        "outputId": "86e07de8-44f6-4b31-fd85-e92ffca96144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 86.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp36-none-any.whl size=97126236 sha256=b7bec7abb4cb24c89439414850373be684b6fd7ae3539651de1bc1af773ed981\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ch7kiov5/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHBjDnlWe1hJ",
        "colab_type": "code",
        "outputId": "4bda3d4b-2b06-4c8e-8ca6-2eea412d7cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Embeddings\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "#tokenizer model\n",
        "nlp_en =spacy.load('en300')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:27, 2.23MB/s]                          \n",
            " 99%|█████████▉| 397621/400000 [00:15<00:00, 24700.26it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed7UHXoUayUO",
        "colab_type": "code",
        "outputId": "ba6a62d7-a224-4d00-eca6-9bfba4846e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#downloading stopwords from the nltk package\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "stop_words_en = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpdCtfu7a0fF",
        "colab_type": "code",
        "outputId": "acf14882-9638-4db8-e9ad-a3b0ab362b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "!wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "!wget -O zh.zip http://vectors.nlpl.eu/repository/20/35.zip\n",
        "\n",
        "!unzip zh.zip \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 397621/400000 [00:33<00:00, 24700.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-02-24 17:06:47--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "chinese_stop_words.     [  <=>               ] 419.55K  1.60MB/s    in 0.3s    \n",
            "\n",
            "2020-02-24 17:06:47 (1.60 MB/s) - ‘chinese_stop_words.txt’ saved [429618]\n",
            "\n",
            "--2020-02-24 17:06:48--  http://vectors.nlpl.eu/repository/20/35.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458485917 (1.4G) [application/zip]\n",
            "Saving to: ‘zh.zip’\n",
            "\n",
            "zh.zip              100%[===================>]   1.36G  16.6MB/s    in 88s     \n",
            "\n",
            "2020-02-24 17:08:17 (15.8 MB/s) - ‘zh.zip’ saved [1458485917/1458485917]\n",
            "\n",
            "Archive:  zh.zip\n",
            "  inflating: LIST                    \n",
            "  inflating: meta.json               \n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa94xvlYa3G8",
        "colab_type": "code",
        "outputId": "8825728b-9b1d-458b-cc3d-b18f41bf2660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWKFoo0dai6d",
        "colab_type": "code",
        "outputId": "5cb02d9f-f4ef-4b05-ade8-c64d9569f352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from os.path import exists\n",
        "\n",
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-24 17:09:15--  https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6a4414e04b135c76e022ac0b9e8eb027d5ed12dee7d311024c1baa1a85a3a828&X-Amz-Date=20200224T170916Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200224%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-02-24 17:09:16--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=6a4414e04b135c76e022ac0b9e8eb027d5ed12dee7d311024c1baa1a85a3a828&X-Amz-Date=20200224T170916Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200224%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 870893 (850K) [application/zip]\n",
            "Saving to: ‘enzh_data.zip’\n",
            "\n",
            "enzh_data.zip       100%[===================>] 850.48K  1.00MB/s    in 0.8s    \n",
            "\n",
            "2020-02-24 17:09:17 (1.00 MB/s) - ‘enzh_data.zip’ saved [870893/870893]\n",
            "\n",
            "Archive:  enzh_data.zip\n",
            "  inflating: dev.enzh.mt             \n",
            "  inflating: dev.enzh.scores         \n",
            "  inflating: dev.enzh.src            \n",
            "  inflating: test.enzh.mt            \n",
            "  inflating: test.enzh.src           \n",
            "  inflating: train.enzh.mt           \n",
            "  inflating: train.enzh.src          \n",
            "  inflating: train.enzh.scores       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9VRR0sSXlnm",
        "colab_type": "text"
      },
      "source": [
        "# Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYhR6_QwO85p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import jieba\n",
        "import gensim \n",
        "import spacy\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import urllib\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from torch.nn import Conv2d, MaxPool2d\n",
        "from scipy.stats.stats import pearsonr\n",
        "from tqdm import tqdm_notebook\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIvkajT4Yo75",
        "colab_type": "text"
      },
      "source": [
        "## load train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSaR3PDqYodB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_train_txt = urllib.request.urlopen('https://raw.githubusercontent.com/chanyikchong/Natural-Language-Process/master/train.enzh.src')\n",
        "english_train = [] \n",
        "for sent in english_train_txt.readlines():\n",
        "  english_train.append(sent.decode('utf-8'))\n",
        "\n",
        "\n",
        "chinese_train_txt = urllib.request.urlopen('https://raw.githubusercontent.com/chanyikchong/Natural-Language-Process/master/train.enzh.mt')\n",
        "chinese_train = [] \n",
        "for sent in chinese_train_txt.readlines():\n",
        "  chinese_train.append(sent.decode('utf-8'))\n",
        "\n",
        "scores_train_txt = urllib.request.urlopen('https://raw.githubusercontent.com/chanyikchong/Natural-Language-Process/master/train.enzh.scores')\n",
        "\n",
        "scores_train = [] \n",
        "for sent in scores_train_txt.readlines():\n",
        "  sent = np.float(sent.decode('utf-8'))\n",
        "  scores_train.append(sent)\n",
        "\n",
        "\n",
        "english_train = np.array(english_train)\n",
        "chinese_train = np.array(chinese_train)\n",
        "scores_train = np.array(scores_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKjtVPt6TgrK",
        "colab_type": "text"
      },
      "source": [
        "## load validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx6BNoyRTjUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "english_val_txt = urllib.request.urlopen('https://raw.githubusercontent.com/chanyikchong/Natural-Language-Process/master/dev.enzh.src')\n",
        "english_val = [] \n",
        "for sent in english_val_txt.readlines():\n",
        "  english_val.append(sent.decode('utf-8'))\n",
        "\n",
        "\n",
        "chinese_val_txt = urllib.request.urlopen('https://raw.githubusercontent.com/chanyikchong/Natural-Language-Process/master/dev.enzh.mt')\n",
        "chinese_val = [] \n",
        "for sent in chinese_val_txt.readlines():\n",
        "  chinese_val.append(sent.decode('utf-8'))\n",
        "\n",
        "\n",
        "\n",
        "scores_val_txt = urllib.request.urlopen('https://raw.githubusercontent.com/chanyikchong/Natural-Language-Process/master/dev.enzh.scores')\n",
        "scores_val = [] \n",
        "for sent in scores_val_txt.readlines():\n",
        "  sent = np.float(sent.decode('utf-8'))\n",
        "  scores_val.append(sent)\n",
        "\n",
        "\n",
        "english_val = np.array(english_val)\n",
        "chinese_val = np.array(chinese_val)\n",
        "scores_val = np.array(scores_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NOkprVcIG9k",
        "colab_type": "text"
      },
      "source": [
        "## Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omM1MKwGIK6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenize the cropus by seperating the words and removing punctuation using glove and jieba \n",
        "def english_preprocess(sentence, nlp):\n",
        "  text = sentence.lower()\n",
        "  doc = [token.lemma_ for token in  nlp.tokenizer(text)]\n",
        "  doc = [word for word in doc if word not in stop_words_en]\n",
        "  doc = [word for word in doc if word.isalpha()]\n",
        "  return doc\n",
        "\n",
        "def chinese_preprocess(sentence):\n",
        "  stop_words = [ line.rstrip() for line in open('./chinese_stop_words.txt',\"r\", encoding=\"utf-8\") ]\n",
        "  seg_list = jieba.lcut(sentence,cut_all=False)\n",
        "  doc = [word for word in seg_list if word not in stop_words]\n",
        "  docs = [e for e in doc if e.isalnum()]\n",
        "  return docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51PAUZ59F4Er",
        "colab_type": "text"
      },
      "source": [
        "## Define a english vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGz3H4c-F7ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define vocabulary class\n",
        "class english_vocabulary(object):\n",
        "  def __init__(self):\n",
        "    self._word2idx = {}\n",
        "    self.idx2word = []\n",
        "    self.add_word('<pad>')\n",
        "    self.add_word('<s>')\n",
        "    self.add_word('</s>')\n",
        "    self.add_word('<unk>')\n",
        "    self._unk_idx = self._word2idx['<unk>']\n",
        "    self.max_sentence_length = 0 #memory the maximum length of the training cropus\n",
        "  def add_word(self, word):  \n",
        "    if word not in self._word2idx:\n",
        "      self.idx2word.append(word)\n",
        "      self._word2idx[word] = len(self.idx2word) - 1\n",
        "\n",
        "  def word2idx(self, word):\n",
        "    #get the idex of a word\n",
        "    return self._word2idx.get(word, self._unk_idx)\n",
        "\n",
        "  def build_vocabulary(self, cropus, nlp):\n",
        "    self.nlp = nlp\n",
        "    self.cropus = cropus\n",
        "    self.sentence_list = []\n",
        "    for line in cropus:\n",
        "      word_num = 0\n",
        "      words = english_preprocess(line, nlp) \n",
        "      for word in words:\n",
        "        word_num += 1\n",
        "        self.add_word(word)\n",
        "      if word_num > self.max_sentence_length:\n",
        "        self.max_sentence_length = word_num\n",
        "      self.sentence_list.append(words)\n",
        "\n",
        "  def convert_idxs_to_words(self, idxs):\n",
        "    return ' '.join(self.idx2word[idx] for idx in idxs)\n",
        "\n",
        "  def convert_words_to_idxs(self, words):\n",
        "    return [self.word2idx(w) for w in words]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.idx2word)\n",
        "  \n",
        "  def equal_length(self, cropus, is_voc_cropus = True):\n",
        "    #make sure the sentences in the cropus have equal length\n",
        "    new_sentence_list = []\n",
        "    if is_voc_cropus:\n",
        "      sentence_list = self.sentence_list\n",
        "    else:\n",
        "      sentence_list = []\n",
        "      for line in cropus:\n",
        "        word_vec = []\n",
        "        words = english_preprocess(line, self.nlp)\n",
        "        sentence_list.append(words)   \n",
        "    for sentence in sentence_list:\n",
        "      if len(sentence) < self.max_sentence_length:\n",
        "        sentence = sentence+(self.max_sentence_length-len(sentence))*['pad']\n",
        "      elif len(sentence) >self.max_sentence_length:\n",
        "        sentence= sentence[:self.max_sentence_length]\n",
        "      new_sentence_list.append(sentence)\n",
        "    return new_sentence_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNDRbQwbQuCd",
        "colab_type": "text"
      },
      "source": [
        "## Chinese vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ynPZBjrS6i3",
        "colab": {}
      },
      "source": [
        "class chinese_vocabulary(english_vocabulary):\n",
        "  def __init__(self):\n",
        "    super(chinese_vocabulary, self).__init__()\n",
        "\n",
        "  def build_vocabulary(self, cropus):\n",
        "    self.cropus = cropus\n",
        "    self.sentence_list = []\n",
        "    for line in cropus:\n",
        "      word_num = 0\n",
        "      words = chinese_preprocess(line)\n",
        "      for word in words:\n",
        "        word_num += 1\n",
        "        self.add_word(word)\n",
        "      if word_num > self.max_sentence_length:\n",
        "        self.max_sentence_length = word_num\n",
        "      self.sentence_list.append(words)\n",
        "\n",
        "  def equal_length(self, cropus, is_voc_cropus = True):\n",
        "    new_sentence_list = []\n",
        "    if is_voc_cropus:\n",
        "      sentence_list = self.sentence_list\n",
        "    else:\n",
        "      sentence_list = []\n",
        "      for line in cropus:\n",
        "        word_vec = []\n",
        "        words = chinese_preprocess(line)\n",
        "        sentence_list.append(words)  \n",
        "    for sentence in sentence_list:\n",
        "      if len(sentence) < self.max_sentence_length:\n",
        "        sentence = sentence+(self.max_sentence_length-len(sentence))*['pad']\n",
        "      elif len(sentence) >self.max_sentence_length:\n",
        "        sentence= sentence[:self.max_sentence_length]\n",
        "      new_sentence_list.append(sentence)\n",
        "    return new_sentence_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FNGNx6iW2Nr",
        "colab_type": "text"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co7kI-IPW6gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A different embedding method but we didn't use it in this file\n",
        "def english_embedding(cropus, embeddings):\n",
        "  sentence_vectors = []\n",
        "  for sentence in cropus:\n",
        "    word_vect = []\n",
        "    for word in sentence:\n",
        "      try:\n",
        "        vector = embeddings.vectors[embeddings.stoi[word]]\n",
        "      except KeyError:\n",
        "        string = str(word)+\" does not exist\"\n",
        "        vector = embeddings.vectors[embeddings.stoi[\"unk\"]]\n",
        "        #print(string)\n",
        "      if vector is not None:\n",
        "        word_vect.append(vector)\n",
        "    word_vect = np.row_stack(word_vect)\n",
        "    sentence_vectors.append(word_vect)\n",
        "  return sentence_vectors\n",
        "\n",
        "def chinese_embedding(cropus):\n",
        "  sentence_vectors = []\n",
        "  for sentence in cropus:\n",
        "    word_vect = []\n",
        "    for word in sentence:\n",
        "      try:\n",
        "        vector = wv_from_bin[word]\n",
        "      except KeyError:\n",
        "        string = str(word)+\" does not exist\"\n",
        "        vector = wv_from_bin[\"unk\"]\n",
        "        #print(string)\n",
        "      if vector is not None:\n",
        "        word_vect.append(vector)\n",
        "    word_vect = np.row_stack(word_vect)\n",
        "    sentence_vectors.append(word_vect)\n",
        "  return sentence_vectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2jhEzzAAZhd",
        "colab_type": "text"
      },
      "source": [
        "The following cell is using BERT embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhwvQUZBVa8W",
        "colab_type": "code",
        "outputId": "e83db34d-f7f7-4243-a67b-bcf476730b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install bert-serving-client\n",
        "!pip install -U bert-serving-server[http]\n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip\n",
        "!unzip chinese_L-12_H-768_A-12.zip\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-client\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/09/aae1405378a848b2e87769ad89a43d6d71978c4e15534ca48e82e723a72f/bert_serving_client-1.10.0-py2.py3-none-any.whl\n",
            "Collecting pyzmq>=17.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/07/cee3d328a2e13f9de1c2b62cced7a389b61ac81424f2e377f3dc9d668282/pyzmq-18.1.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (1.17.5)\n",
            "Installing collected packages: pyzmq, bert-serving-client\n",
            "  Found existing installation: pyzmq 17.0.0\n",
            "    Uninstalling pyzmq-17.0.0:\n",
            "      Successfully uninstalled pyzmq-17.0.0\n",
            "Successfully installed bert-serving-client-1.10.0 pyzmq-18.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-server[http]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (18.1.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.12.0)\n",
            "Collecting GPUtil>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: bert-serving-client; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.10.0)\n",
            "Collecting flask-cors; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: flask; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.1)\n",
            "Collecting flask-json; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/2d/4c21d98b11f3a206fabbdd965b53a2ca3ee9fab7646c93cf36c060e8f1a4/Flask_JSON-0.3.4-py3-none-any.whl\n",
            "Collecting flask-compress; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/2a/378bd072928f6d92fd8c417d66b00c757dc361c0405a46a0134de6fd323d/Flask-Compress-1.4.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (2.11.1)\n",
            "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask; extra == \"http\"->bert-serving-server[http]) (1.1.1)\n",
            "Building wheels for collected packages: GPUtil, flask-compress\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=c962e34ed5b6acf6eafaa5d70a37888e4cbf72c107bec72fed62b3cb579bf36b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "  Building wheel for flask-compress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-compress: filename=Flask_Compress-1.4.0-cp36-none-any.whl size=3712 sha256=206749bc21355dccd2dbee8b9d1071beb077b4d7f16954363b3903836cc1e305\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/32/88/a1f6d9dd3c29570ab3a8acc0d556b3b20abcf3c623c868ce0a\n",
            "Successfully built GPUtil flask-compress\n",
            "Installing collected packages: GPUtil, flask-cors, flask-json, flask-compress, bert-serving-server\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-server-1.10.0 flask-compress-1.4.0 flask-cors-3.0.8 flask-json-0.3.4\n",
            "--2020-02-24 17:09:31--  https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381892918 (364M) [application/zip]\n",
            "Saving to: ‘chinese_L-12_H-768_A-12.zip’\n",
            "\n",
            "chinese_L-12_H-768_ 100%[===================>] 364.20M  35.3MB/s    in 10s     \n",
            "\n",
            "2020-02-24 17:09:42 (35.3 MB/s) - ‘chinese_L-12_H-768_A-12.zip’ saved [381892918/381892918]\n",
            "\n",
            "Archive:  chinese_L-12_H-768_A-12.zip\n",
            "   creating: chinese_L-12_H-768_A-12/\n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: chinese_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_config.json  \n",
            "--2020-02-24 17:09:48--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   101MB/s    in 3.9s    \n",
            "\n",
            "2020-02-24 17:09:52 (101 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtOEa0GkWZZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nohup bert-serving-start -model_dir=./chinese_L-12_H-768_A-12 > out.file 2>&1 &\n",
        "!nohup bert-serving-start -model_dir=./uncased_L-12_H-768_A-12 > out.file 2>&1 &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J15edzH3WHcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bert_serving.client import BertClient\n",
        "\n",
        "def english_bert(cropus):\n",
        "  bc = BertClient()\n",
        "  sentence_vectors = []\n",
        "  for sentence in cropus:\n",
        "    sentence = bc.encode(sentence)\n",
        "    sentence_vectors.append(sentence)\n",
        "  bc.close()\n",
        "  return sentence_vectors\n",
        "\n",
        "\n",
        "\n",
        "def chinese_bert(cropus):\n",
        "  bc = BertClient()\n",
        "  sentence_vectors = []\n",
        "  for sentence in cropus:\n",
        "    sentence = bc.encode(sentence)\n",
        "    sentence_vectors.append(sentence)\n",
        "  bc.close()\n",
        "  return sentence_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9TxrPPO_Xrh",
        "colab_type": "text"
      },
      "source": [
        "# Define model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DA_f_S0AzLc",
        "colab_type": "text"
      },
      "source": [
        "RNN model with embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsRJfRU_eCcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNLM(nn.Module):\n",
        "  #The RNN class for model having embedding layer\n",
        "  #vocab_size_en: vocabulary size of english\n",
        "  #vocab_size_zh: vocabulary size of english\n",
        "  #emb_dim: the embedding dimension in embedding layer\n",
        "  #hid_dim: the hidden dimension size\n",
        "  #rnn_type: RNN type can choose 'LSTM' 'GRU'\n",
        "  #n_layers: number of hidden layers in RNN\n",
        "  #dropout: the probability of dropout\n",
        "  #bidirectional: the sequence train from both direction\n",
        "  #the other two argument are useless but important and \n",
        "  #please do not change it if you don't understant the RNN structure in pytorch\n",
        "  def __init__(self, vocab_size_en, vocab_size_zh, emb_dim, hid_dim, rnn_type='RNN',\n",
        "               n_layers=1, dropout=0.5, clip_gradient_norm=1.0, batch_first = False, bidirectional=False):\n",
        "    # Call parent's __init__ first\n",
        "    super(RNNLM, self).__init__()\n",
        "    \n",
        "    # Store arguments\n",
        "    self.vocab_size_en = vocab_size_en\n",
        "    self.vocab_size_zh = vocab_size_zh\n",
        "    self.emb_dim = emb_dim\n",
        "    self.hid_dim = hid_dim\n",
        "    self.clip_gradient_norm = clip_gradient_norm\n",
        "    self.n_layers = n_layers\n",
        "    self.rnn_type = rnn_type.upper()\n",
        "    self.batch_first = batch_first\n",
        "    self.bidirectional = bidirectional\n",
        "\n",
        "    # This will be used to store the detached histories for truncated BPTT\n",
        "    self.prev_histories_en = None\n",
        "    self.prev_histories_zh = None\n",
        "    \n",
        "    # Create the dropout\n",
        "    self.drop = nn.Dropout(p=dropout)\n",
        "    \n",
        "    # Create the embedding layer as usual\n",
        "    self.emb_en = nn.Embedding(\n",
        "      num_embeddings=self.vocab_size_en, embedding_dim=self.emb_dim,\n",
        "      padding_idx=0)\n",
        "    \n",
        "    self.emb_zh = nn.Embedding(\n",
        "      num_embeddings=self.vocab_size_zh, embedding_dim=self.emb_dim,\n",
        "      padding_idx=0)\n",
        "\n",
        "    # Create the RNN layer\n",
        "    if self.rnn_type == 'RNN':\n",
        "      self.rnn_en = nn.RNN( \n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim,\n",
        "          num_layers=self.n_layers, nonlinearity='tanh', batch_first = batch_first, bidirectional = bidirectional)\n",
        "      self.rnn_zh = nn.RNN( \n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim,\n",
        "          num_layers=self.n_layers, nonlinearity='tanh', batch_first = batch_first, bidirectional = bidirectional)\n",
        "    elif self.rnn_type == 'GRU':\n",
        "      self.rnn_en = nn.GRU(\n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim,\n",
        "          num_layers=self.n_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
        "      self.rnn_zh = nn.GRU(\n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim,\n",
        "          num_layers=self.n_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
        "    elif self.rnn_type == 'LSTM':\n",
        "      self.rnn_en = nn.LSTM(\n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim, \n",
        "          num_layers=self.n_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
        "      self.rnn_zh = nn.LSTM(\n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim, \n",
        "          num_layers=self.n_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
        "      \n",
        "    self.linear1 = nn.Linear(self.hid_dim*2, 64)\n",
        "    self.linear2 = nn.Linear(64, 1)\n",
        "    \n",
        "    if self.bidirectional:\n",
        "      self.out = nn.Linear(self.hid_dim*2, 1)\n",
        "    else:\n",
        "      self.out = nn.Linear(self.hid_dim, 1)\n",
        "\n",
        "  def init_state(self, batch_size):\n",
        "    \"\"\"Returns the initial 0 states.\"\"\"\n",
        "    if not self.bidirectional:\n",
        "      if self.rnn_type != 'LSTM':\n",
        "        return torch.zeros(self.n_layers, batch_size, self.hid_dim, device=device)\n",
        "      else:\n",
        "        return (torch.zeros(self.n_layers, batch_size, self.hid_dim, device=device),\n",
        "                torch.zeros(self.n_layers, batch_size, self.hid_dim, device=device))\n",
        "    else:\n",
        "      if self.rnn_type != 'LSTM':\n",
        "        return torch.zeros(self.n_layers*2, batch_size, self.hid_dim, device=device)\n",
        "      else:\n",
        "        return (torch.zeros(self.n_layers*2, batch_size, self.hid_dim, device=device),\n",
        "                torch.zeros(self.n_layers*2, batch_size, self.hid_dim, device=device))\n",
        "\n",
        "  def clear_hidden_states(self):\n",
        "    \"\"\"Set the relevant instance attribute to None.\"\"\"\n",
        "    self.prev_histories_en = None\n",
        "    self.prev_histories_zh = None\n",
        "\n",
        "  def save_hidden_states(self, last_states_en, last_states_zh):\n",
        "    \"\"\"Save the detached states into the model for the next batch. `last_states`\n",
        "    is the second return value of RNN/GRU/LSTM's forward() methods.\"\"\"\n",
        "    if isinstance(last_states_en, tuple):\n",
        "      # This is true for LSTM\n",
        "      self.prev_histories_en = tuple(r.detach() for r in last_states_en)\n",
        "      self.prev_histories_zh = tuple(r.detach() for r in last_states_zh)\n",
        "    else:\n",
        "      self.prev_histories_en = last_states_en.detach()\n",
        "      self.prev_histories_zh = last_states_zh.detach()\n",
        "\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    \"\"\"Forward-pass of the module.\"\"\"\n",
        "    if self.batch_first:\n",
        "      if self.prev_histories_en is None or self.prev_histories_zh is None:\n",
        "        self.prev_histories_en = self.init_state(x.shape[0])\n",
        "        self.prev_histories_zh = self.init_state(y.shape[0])\n",
        "    else:\n",
        "      if self.prev_histories_en is None or self.prev_histories_zh is None:\n",
        "        self.prev_histories_en = self.init_state(x.shape[1])\n",
        "        self.prev_histories_zh = self.init_state(y.shape[1])\n",
        "\n",
        "    # Tokens -> Embeddings -> Dropout\n",
        "    embs_en = self.drop(self.emb_en(x))\n",
        "    embs_zh = self.drop(self.emb_zh(y))\n",
        "    all_hids_en, last_hid_en = self.rnn_en(embs_en, self.prev_histories_en)\n",
        "    all_hids_zh, last_hid_zh = self.rnn_zh(embs_zh, self.prev_histories_zh)\n",
        "\n",
        "    # Detach the computation graph since we are done with BPTT for this batch\n",
        "    self.save_hidden_states(last_hid_en, last_hid_zh)\n",
        "\n",
        "    logits_en = self.drop(all_hids_en)\n",
        "    logits_zh = self.drop(all_hids_zh)\n",
        "    if self.batch_first:\n",
        "      logits_en = torch.mean(logits_en, dim = 1)\n",
        "      logits_zh = torch.mean(logits_zh, dim = 1)\n",
        "      out = self.out((logits_en+logits_zh)/2)\n",
        "    else:\n",
        "      logits_en = torch.mean(logits_en, dim = 0)\n",
        "      logits_zh = torch.mean(logits_zh, dim = 0)\n",
        "      out = self.out((logits_en+logits_zh)/2)\n",
        "\n",
        "\n",
        "    return out\n",
        " \n",
        "\n",
        "  def __repr__(self):\n",
        "    \"\"\"String representation for pretty-printing.\"\"\"\n",
        "    s = super(RNNLM, self).__repr__()\n",
        "    return \"{}\\n# of parameters: {}\".format(s, self.n_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqaU9fSQAu--",
        "colab_type": "text"
      },
      "source": [
        "RNN model with pre-train embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doXRgeMCE0un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreRNN(RNNLM):\n",
        "  #The RNN class for model with pre-train embedding\n",
        "  #It is a successor of the RNNLM class\n",
        "  #vocab_size_en: vocabulary size of english\n",
        "  #vocab_size_zh: vocabulary size of english\n",
        "  #emb_dim: the embedding dimension in embedding layer \"useless in this class\"\n",
        "  #hid_dim: the hidden dimension size\n",
        "  #rnn_type: RNN type can choose 'LSTM' 'GRU'\n",
        "  #n_layers: number of hidden layers in RNN\n",
        "  #dropout: the probability of dropout\n",
        "  #bidirectional: the sequence train from both direction\n",
        "  #the other two argument are useless but important and \n",
        "  #please do not change it if you don't understant the RNN structure in pytorch\n",
        "  def __init__(self, vocab_size_en, vocab_size_zh, emb_dim, hid_dim, rnn_type='RNN',\n",
        "               n_layers=1, dropout=0.5, clip_gradient_norm=1.0, batch_first = False, bidirectional=False):\n",
        "    super(RNNLM, self).__init__()\n",
        "\n",
        "    self.vocab_size_en = vocab_size_en\n",
        "    self.vocab_size_zh = vocab_size_zh\n",
        "    self.emb_dim = emb_dim\n",
        "    self.hid_dim = hid_dim\n",
        "    self.clip_gradient_norm = clip_gradient_norm\n",
        "    self.n_layers = n_layers\n",
        "    self.rnn_type = rnn_type.upper()\n",
        "    self.batch_first = batch_first\n",
        "    self.bidirectional = bidirectional\n",
        "\n",
        "    # This will be used to store the detached histories for truncated BPTT\n",
        "    self.prev_histories_en = None\n",
        "    self.prev_histories_zh = None\n",
        "    \n",
        "    # Create the dropout\n",
        "    self.drop = nn.Dropout(p=dropout)\n",
        "    \n",
        "    # Create the embedding layer as usual\n",
        "    self.emb_en = nn.Embedding(\n",
        "      num_embeddings=self.vocab_size_en, embedding_dim=self.emb_dim,\n",
        "      padding_idx=0)\n",
        "    \n",
        "    self.emb_zh = nn.Embedding(\n",
        "      num_embeddings=self.vocab_size_zh, embedding_dim=self.emb_dim,\n",
        "      padding_idx=0)\n",
        "\n",
        "    # Create the RNN layer\n",
        "    if self.rnn_type == 'RNN':\n",
        "      self.rnn_en = nn.RNN( \n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim,\n",
        "          num_layers=self.n_layers, nonlinearity='tanh', batch_first = batch_first, bidirectional = bidirectional)\n",
        "      self.rnn_zh = nn.RNN( \n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim,\n",
        "          num_layers=self.n_layers, nonlinearity='tanh', batch_first = batch_first, bidirectional = bidirectional)\n",
        "    elif self.rnn_type == 'GRU':\n",
        "      self.rnn_en = nn.GRU(\n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim,\n",
        "          num_layers=self.n_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
        "      self.rnn_zh = nn.GRU(\n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim,\n",
        "          num_layers=self.n_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
        "    elif self.rnn_type == 'LSTM':\n",
        "      self.rnn_en = nn.LSTM(\n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim, \n",
        "          num_layers=self.n_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
        "      self.rnn_zh = nn.LSTM(\n",
        "          input_size=self.emb_dim, hidden_size=self.hid_dim, \n",
        "          num_layers=self.n_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
        "      \n",
        "    self.linear1 = nn.Linear(self.hid_dim*2, 64)\n",
        "    self.linear2 = nn.Linear(64, 1)\n",
        "    \n",
        "    if self.bidirectional:\n",
        "      self.out = nn.Linear(self.hid_dim*2, 1)\n",
        "    else:\n",
        "      self.out = nn.Linear(self.hid_dim, 1)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    if self.batch_first:\n",
        "      if self.prev_histories_en is None or self.prev_histories_zh is None:\n",
        "        self.prev_histories_en = self.init_state(x.shape[0])\n",
        "        self.prev_histories_zh = self.init_state(y.shape[0])\n",
        "    else:\n",
        "      if self.prev_histories_en is None or self.prev_histories_zh is None:\n",
        "        self.prev_histories_en = self.init_state(x.shape[1])\n",
        "        self.prev_histories_zh = self.init_state(y.shape[1])\n",
        "\n",
        "    embs_en = x\n",
        "    embs_zh = y\n",
        "    all_hids_en, last_hid_en = self.rnn_en(embs_en, self.prev_histories_en)\n",
        "    all_hids_zh, last_hid_zh = self.rnn_zh(embs_zh, self.prev_histories_zh)\n",
        "\n",
        "    # Detach the computation graph since we are done with BPTT for this batch\n",
        "    self.save_hidden_states(last_hid_en, last_hid_zh)\n",
        "\n",
        "    logits_en = self.drop(all_hids_en)\n",
        "    logits_zh = self.drop(all_hids_zh)\n",
        "    if self.batch_first:\n",
        "      logits_en = torch.mean(logits_en, dim = 1)\n",
        "      logits_zh = torch.mean(logits_zh, dim = 1)\n",
        "      out = self.out((logits_en+logits_zh)/2)\n",
        "    else:\n",
        "      logits_en = torch.mean(logits_en, dim = 0)\n",
        "      logits_zh = torch.mean(logits_zh, dim = 0)\n",
        "      out = self.out((logits_en+logits_zh)/2)\n",
        "\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp1M5BrZ1tmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, optim, train_loader, valid_loader, n_epochs=5):\n",
        "  \"\"\"Trains the model.\"\"\"\n",
        "\n",
        "  epoch_loss_list_train = []\n",
        "  pearson_list_train = []\n",
        "  loss_val = []\n",
        "  pearson_val = []\n",
        "  for eidx in tqdm_notebook(range(1, n_epochs + 1)):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_items = 0\n",
        "    pearson_correlation = 0\n",
        "    # Enable training mode\n",
        "    model.train()\n",
        "    count = 0\n",
        "    for iter_count, (x, y, z) in enumerate(train_loader):\n",
        "      # Clear the gradients\n",
        "      optim.zero_grad()\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      z = z.to(device)\n",
        "      out = model.forward(x, y)\n",
        "\n",
        "      # Backprop the average loss and update parameters\n",
        "      loss = F.mse_loss(out, z)\n",
        "      loss.backward()\n",
        "\n",
        "      # Clip the gradients to avoid exploding gradients\n",
        "      '''\n",
        "      if self.clip_gradient_norm > 0:\n",
        "        torch.nn.utils.clip_grad_norm_(self.parameters(), self.clip_gradient_norm)\n",
        "      '''\n",
        "\n",
        "      # Update parameters\n",
        "      optim.step()\n",
        "\n",
        "      # sum the loss for reporting, along with the denominator\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_items += loss.numel()\n",
        "\n",
        "      pearson_correlation += pearsonr(out.reshape(-1).detach().cpu(), z.reshape(-1).cpu())[0]\n",
        "      count += 1\n",
        "    # Clear stale h_t history before evaluation\n",
        "    model.clear_hidden_states()\n",
        "\n",
        "    loss_per_token = epoch_loss / count\n",
        "    print(f'\\n[Epoch {eidx:<3}] ended with train_loss: {loss_per_token:6.2f}')\n",
        "    pearson_correlation /=count\n",
        "    print('Pearson (%.4f)' % (pearson_correlation))\n",
        "    \n",
        "  \n",
        "  \n",
        "  # Evaluate the final model on test set\n",
        "    test_loss, pearson = evaluate(model, valid_loader)\n",
        "    print(f'test set performance: {test_loss:6.2f}, pearson: {pearson:6.2f}')\n",
        "    epoch_loss_list_train.append(loss_per_token)\n",
        "    pearson_list_train.append(pearson_correlation)\n",
        "    loss_val.append(test_loss)\n",
        "    pearson_val.append(pearson)\n",
        "  return epoch_loss_list_train, pearson_list_train, loss_val, pearson_val\n",
        "\n",
        "def evaluate(model, batches):\n",
        "  # Clear stale h_t history before evaluation\n",
        "  model.clear_hidden_states()\n",
        "\n",
        "  # Switch to eval mode\n",
        "  model.eval()\n",
        "  count = 0\n",
        "  total_loss = 0.\n",
        "  total_tokens = 0\n",
        "  pearson_correlation = 0\n",
        "  with torch.no_grad():\n",
        "    for iter_count, (x, y, z) in enumerate(batches):\n",
        "\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      z = z.to(device)\n",
        "      out = model.forward(x, y)\n",
        "      loss = F.mse_loss(out, z)\n",
        "      \n",
        "      pearson_correlation += pearsonr(out.reshape(-1).detach().cpu(), z.reshape(-1).cpu())[0]\n",
        "      total_loss += loss.item()\n",
        "      total_tokens += 1\n",
        "      count += 1\n",
        "  total_loss /= count\n",
        "  pearson = pearson_correlation / count\n",
        "  model.clear_hidden_states()\n",
        "  return total_loss, pearson"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-_6T4YWFeGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datacombine(english_list, chinese_list, score_list):\n",
        "  #combine the english data, chinese data and score data\n",
        "  #so that we can use dataloader to batch the data\n",
        "  dataset = []\n",
        "  for i in range(len(score_list)):\n",
        "    sample = (english_list[i], chinese_list[i], score_list[i])\n",
        "    dataset.append(sample)\n",
        "  return dataset\n",
        "\n",
        "def sentence_list_to_tensor(sentence_list):\n",
        "  #convert list to tensor\n",
        "  sentence_tensor = torch.FloatTensor(sentence_list)\n",
        "  shape = sentence_tensor.shape\n",
        "  sentence_tensor = sentence_tensor.reshape(shape[0], shape[1], shape[2])\n",
        "  return sentence_tensor\n",
        "\n",
        "def word_2_idx(voca, cropus):\n",
        "  #get the idx of the word in the sentence list\n",
        "  idxs = []\n",
        "  for sentence in cropus:\n",
        "    idx = voca.convert_words_to_idxs(sentence)\n",
        "    idxs.append(idx)\n",
        "  return torch.LongTensor(idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCfoOQC4A7FU",
        "colab_type": "text"
      },
      "source": [
        "# Start training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArY_nlOyBA8H",
        "colab_type": "text"
      },
      "source": [
        "## Train model with embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFvVZ8lO-lfy",
        "colab_type": "code",
        "outputId": "b74347c0-99f2-41f2-b86c-db0062968b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "voc_eng = english_vocabulary()\n",
        "voc_eng.build_vocabulary(english_train, nlp_en)\n",
        "\n",
        "voc_zh = chinese_vocabulary()\n",
        "voc_zh.build_vocabulary(chinese_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.603 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoBfo17E9dUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "equal_length_eng_train = voc_eng.equal_length(english_train)\n",
        "idx_list_en = word_2_idx(voc_eng,equal_length_eng_train)\n",
        "\n",
        "equal_length_zh_train = voc_zh.equal_length(chinese_train)\n",
        "idx_list_zh = word_2_idx(voc_zh,equal_length_zh_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwbrJAfn-pUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_list_en = torch.LongTensor(idx_list_en)\n",
        "idx_list_zh = torch.LongTensor(idx_list_zh)\n",
        "\n",
        "scores_train = torch.FloatTensor(scores_train).reshape(-1,1)\n",
        "train_loader = datacombine(idx_list_en, idx_list_zh, scores_train)\n",
        "\n",
        "loader_train = DataLoader(train_loader, batch_size=70, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ-hwTBAGyIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_list_en_val = voc_eng.equal_length(english_val, is_voc_cropus=False)\n",
        "idx_list_en_val = torch.LongTensor(word_2_idx(voc_eng, sentence_list_en_val))\n",
        "\n",
        "sentence_list_zh_val = voc_zh.equal_length(chinese_val, is_voc_cropus=False)\n",
        "idx_list_zh_val = torch.LongTensor(word_2_idx(voc_zh, sentence_list_zh_val))\n",
        "\n",
        "scores_val = torch.FloatTensor(scores_val).reshape(-1,1)\n",
        "val_loader = datacombine(idx_list_en_val, idx_list_zh_val, scores_val)\n",
        "loader_val = DataLoader(val_loader, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szp2Mr-qHiKE",
        "colab_type": "code",
        "outputId": "bbb4f5f0-dc59-4879-f6f7-ee89e6be5244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734,
          "referenced_widgets": [
            "4c6c6cc539864fcfb687d6167540870d",
            "76121b41412942db8f10d4a70f07ee3d",
            "602d763d9eda40b99a421bb9ac7aa2a4",
            "d7195b068524495d90eba1fd04e0e96d",
            "e2c179be10314ee099e2f184631cf9a1",
            "3670f80401cd4b8491938b83ee02c4be",
            "c75757d71f434bae9709815266b98d00",
            "c518b896402e405e80974eb0160e50f7"
          ]
        }
      },
      "source": [
        "device = 'cuda'\n",
        "\n",
        "model = RNNLM(len(voc_eng.idx2word), len(voc_zh.idx2word), 50, 256, rnn_type='GRU',\n",
        "               n_layers=4, dropout=0.1, clip_gradient_norm=1.0, batch_first = True, bidirectional = False)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "lo_train, per_train, lo_val, per_val = train_model(model, optimizer, loader_train, loader_val, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c6c6cc539864fcfb687d6167540870d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 1  ] ended with train_loss:   0.86\n",
            "Pearson (0.0998)\n",
            "test set performance:   0.82, pearson:   0.11\n",
            "\n",
            "[Epoch 2  ] ended with train_loss:   0.85\n",
            "Pearson (0.1589)\n",
            "test set performance:   0.82, pearson:   0.11\n",
            "\n",
            "[Epoch 3  ] ended with train_loss:   0.81\n",
            "Pearson (0.2638)\n",
            "test set performance:   0.83, pearson:   0.12\n",
            "\n",
            "[Epoch 4  ] ended with train_loss:   0.74\n",
            "Pearson (0.4069)\n",
            "test set performance:   0.88, pearson:   0.14\n",
            "\n",
            "[Epoch 5  ] ended with train_loss:   0.63\n",
            "Pearson (0.5312)\n",
            "test set performance:   0.95, pearson:   0.13\n",
            "\n",
            "[Epoch 6  ] ended with train_loss:   0.52\n",
            "Pearson (0.6444)\n",
            "test set performance:   0.97, pearson:   0.13\n",
            "\n",
            "[Epoch 7  ] ended with train_loss:   0.41\n",
            "Pearson (0.7346)\n",
            "test set performance:   0.99, pearson:   0.12\n",
            "\n",
            "[Epoch 8  ] ended with train_loss:   0.31\n",
            "Pearson (0.8051)\n",
            "test set performance:   1.01, pearson:   0.11\n",
            "\n",
            "[Epoch 9  ] ended with train_loss:   0.24\n",
            "Pearson (0.8526)\n",
            "test set performance:   1.03, pearson:   0.12\n",
            "\n",
            "[Epoch 10 ] ended with train_loss:   0.18\n",
            "Pearson (0.8908)\n",
            "test set performance:   1.11, pearson:   0.13\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u290_EtPBg96",
        "colab_type": "text"
      },
      "source": [
        "## Train model with pre-train embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoU3tTrgXyoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc_zh = chinese_vocabulary() #Create chinese vocabulary\n",
        "voc_zh.build_vocabulary(chinese_train)\n",
        "sentence_list_zh = voc_zh.equal_length(chinese_train)\n",
        "sentence_vector_zh = chinese_bert(sentence_list_zh) #use the BERT embedding\n",
        "sentence_vector_zh = sentence_list_to_tensor(sentence_vector_zh) #Convert to tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FixnSpkmWB0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do the same thing to english\n",
        "voc_eng = english_vocabulary() \n",
        "voc_eng.build_vocabulary(english_train, nlp_en)\n",
        "sentence_list_en = voc_eng.equal_length(english_train)\n",
        "sentence_vector_en = english_bert(sentence_list_en)\n",
        "sentence_vector_en = sentence_list_to_tensor(sentence_vector_en)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuGIcLbEiyeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores_train = torch.FloatTensor(scores_train).reshape(-1,1)\n",
        "\n",
        "data_loader = datacombine(sentence_vector_en, sentence_vector_zh, scores_train)\n",
        "\n",
        "\n",
        "NUM_TRAIN = len(scores_train)\n",
        "loader_train = DataLoader(data_loader, batch_size=70, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUMH-prli16Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_list_en_val = voc_eng.equal_length(english_val, is_voc_cropus=False)\n",
        "sentence_vector_en_val = english_bert(sentence_list_en_val)\n",
        "sentence_vector_en_val = sentence_list_to_tensor(sentence_vector_en_val)\n",
        "\n",
        "sentence_list_zh_val = voc_zh.equal_length(chinese_val, is_voc_cropus=False)\n",
        "sentence_vector_zh_val = chinese_bert(sentence_list_zh_val)\n",
        "sentence_vector_zh_val = sentence_list_to_tensor(sentence_vector_zh_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG7AZCCoi5te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores_val = torch.FloatTensor(scores_val).reshape(-1,1)\n",
        "val_loader = datacombine(sentence_vector_en_val, sentence_vector_zh_val, scores_val)\n",
        "\n",
        "NUM_VAL = len(scores_val)\n",
        "loader_val = DataLoader(val_loader, batch_size=NUM_VAL, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_VAL)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQPNmne1i_Bd",
        "colab_type": "code",
        "outputId": "a9518249-1f84-409c-ea64-0a7850c6b9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "78aebb861fc3489b9844d566e5b49466",
            "e1f45e88ee6948889a34f14f139c380f",
            "58a019b309ad461e90256b1f5a48e504",
            "aef5e9fa02c84325a9180afd654a9e73",
            "28648255724042df96e6049882560ca1",
            "cd986fb29c7249c6877d80c38440f6c4",
            "5de64b3e6a3746088ac3f7354e7ce250",
            "b62c3bc4280b4f1ea8f92c36ad1c27ae"
          ]
        }
      },
      "source": [
        "device = 'cuda'\n",
        "\n",
        "model = PreRNN(len(voc_eng.idx2word), len(voc_zh.idx2word), 768, 1024, rnn_type='GRU',\n",
        "               n_layers=2, dropout=0.5, clip_gradient_norm=1.0, batch_first = True, bidirectional = False)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 2e-4)\n",
        "\n",
        "\n",
        "lo_train, per_train, lo_val, per_val = train_model(model, optimizer, loader_train, loader_val, 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78aebb861fc3489b9844d566e5b49466",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 1  ] ended with train_loss:   0.93\n",
            "Pearson (0.1068)\n",
            "test set performance:   0.82, pearson:   0.13\n",
            "\n",
            "[Epoch 2  ] ended with train_loss:   0.84\n",
            "Pearson (0.2138)\n",
            "test set performance:   0.79, pearson:   0.22\n",
            "\n",
            "[Epoch 3  ] ended with train_loss:   0.80\n",
            "Pearson (0.2953)\n",
            "test set performance:   0.78, pearson:   0.25\n",
            "\n",
            "[Epoch 4  ] ended with train_loss:   0.78\n",
            "Pearson (0.3337)\n",
            "test set performance:   0.81, pearson:   0.27\n",
            "\n",
            "[Epoch 5  ] ended with train_loss:   0.76\n",
            "Pearson (0.3686)\n",
            "test set performance:   0.78, pearson:   0.26\n",
            "\n",
            "[Epoch 6  ] ended with train_loss:   0.73\n",
            "Pearson (0.4160)\n",
            "test set performance:   0.77, pearson:   0.27\n",
            "\n",
            "[Epoch 7  ] ended with train_loss:   0.70\n",
            "Pearson (0.4614)\n",
            "test set performance:   0.78, pearson:   0.26\n",
            "\n",
            "[Epoch 8  ] ended with train_loss:   0.66\n",
            "Pearson (0.5080)\n",
            "test set performance:   0.85, pearson:   0.24\n",
            "\n",
            "[Epoch 9  ] ended with train_loss:   0.60\n",
            "Pearson (0.5733)\n",
            "test set performance:   0.90, pearson:   0.21\n",
            "\n",
            "[Epoch 10 ] ended with train_loss:   0.51\n",
            "Pearson (0.6425)\n",
            "test set performance:   0.90, pearson:   0.20\n",
            "\n",
            "[Epoch 11 ] ended with train_loss:   0.43\n",
            "Pearson (0.7172)\n",
            "test set performance:   0.94, pearson:   0.20\n",
            "\n",
            "[Epoch 12 ] ended with train_loss:   0.35\n",
            "Pearson (0.7808)\n",
            "test set performance:   0.99, pearson:   0.18\n",
            "\n",
            "[Epoch 13 ] ended with train_loss:   0.30\n",
            "Pearson (0.8251)\n",
            "test set performance:   1.03, pearson:   0.17\n",
            "\n",
            "[Epoch 14 ] ended with train_loss:   0.21\n",
            "Pearson (0.8729)\n",
            "test set performance:   1.01, pearson:   0.19\n",
            "\n",
            "[Epoch 15 ] ended with train_loss:   0.15\n",
            "Pearson (0.9090)\n",
            "test set performance:   1.10, pearson:   0.17\n",
            "\n",
            "[Epoch 16 ] ended with train_loss:   0.12\n",
            "Pearson (0.9288)\n",
            "test set performance:   1.01, pearson:   0.18\n",
            "\n",
            "[Epoch 17 ] ended with train_loss:   0.10\n",
            "Pearson (0.9443)\n",
            "test set performance:   1.11, pearson:   0.15\n",
            "\n",
            "[Epoch 18 ] ended with train_loss:   0.07\n",
            "Pearson (0.9582)\n",
            "test set performance:   1.03, pearson:   0.15\n",
            "\n",
            "[Epoch 19 ] ended with train_loss:   0.06\n",
            "Pearson (0.9665)\n",
            "test set performance:   1.06, pearson:   0.15\n",
            "\n",
            "[Epoch 20 ] ended with train_loss:   0.05\n",
            "Pearson (0.9725)\n",
            "test set performance:   1.06, pearson:   0.18\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD7_pa5tHowK",
        "colab_type": "code",
        "outputId": "852e40a0-0da5-4ca7-9585-e7abd852ffba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(len(lo_train)), lo_train, label = 'training loss')\n",
        "plt.plot(range(len(lo_train)), lo_val, label = 'validation loss')\n",
        "plt.plot(range(len(lo_train)), per_train, label = 'training pearson')\n",
        "plt.plot(range(len(lo_train)), per_val, label = 'validation pearson')\n",
        "plt.legend()\n",
        "plt.savefig('GRU.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_agmvkMu-VVP",
        "colab_type": "text"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bCYnsxc-XVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")\n",
        "\n",
        "\n",
        "english_test_txt = urllib.request.urlopen('https://raw.githubusercontent.com/chanyikchong/Natural-Language-Process/master/test.enzh.src')\n",
        "english_test = [] \n",
        "for sent in english_test_txt.readlines():\n",
        "  english_test.append(sent.decode('utf-8'))\n",
        "\n",
        "\n",
        "chinese_test_txt = urllib.request.urlopen('https://raw.githubusercontent.com/chanyikchong/Natural-Language-Process/master/test.enzh.mt')\n",
        "chinese_test = [] \n",
        "for sent in chinese_test_txt.readlines():\n",
        "  chinese_test.append(sent.decode('utf-8'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWUkkw1fCxc2",
        "colab_type": "text"
      },
      "source": [
        "Result on model with embedding layer and please import the test data again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNl5Rd9JC11n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_test = voc_eng.equal_length(english_test, is_voc_cropus=False)\n",
        "english_test = word_2_idx(voc_eng, english_test)\n",
        "\n",
        "\n",
        "chinese_test = voc_zh.equal_length(chinese_test, is_voc_cropus=False)\n",
        "chinese_test = word_2_idx(voc_zh,chinese_test)\n",
        "\n",
        "english_test = torch.LongTensor(english_test)\n",
        "chinese_test = torch.LongTensor(chinese_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huf86tYkCp4O",
        "colab_type": "text"
      },
      "source": [
        "Result on pre-train embedding and please import the test data again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH0pQNsHCmY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_test = voc_eng.equal_length(english_test, is_voc_cropus=False)\n",
        "english_test = english_bert(english_test)\n",
        "english_test = sentence_list_to_tensor(english_test)\n",
        "\n",
        "\n",
        "chinese_test = voc_zh.equal_length(chinese_test, is_voc_cropus=False)\n",
        "chinese_test = chinese_bert(chinese_test)\n",
        "chinese_test = sentence_list_to_tensor(chinese_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA8tVrYTDxca",
        "colab_type": "text"
      },
      "source": [
        "The rest are the same for two models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzOgYLn2-9sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_test = english_test.to(device)\n",
        "chinese_test = chinese_test.to(device)\n",
        "model.eval()\n",
        "predictions_zh = model(english_test, chinese_test)\n",
        "predictions_zh = predictions_zh.cpu()\n",
        "predictions_zh = predictions_zh.detach().numpy()\n",
        "predictions_zh = predictions_zh.reshape(-1,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q64SXlak-999",
        "colab_type": "code",
        "outputId": "29edf04b-abab-4482-da9f-a5bad35e3dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "writeScores(\"RNN\",predictions_zh)\n",
        "\n",
        "with ZipFile(\"en-zh_RNN.zip\",\"w\") as newzip:\n",
        "\tnewzip.write(\"predictions.txt\")\n",
        " \n",
        "files.download('en-zh_RNN.zip') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}